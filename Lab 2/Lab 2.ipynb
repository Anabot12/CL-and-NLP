{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_21120\\865570651.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ds['review_processed'] = ds['review_processed'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing stopwords:\n",
      "0      One reviewers mentioned watching episode hooke...\n",
      "1      wonderful little production br br filming tech...\n",
      "2      thought wonderful way spend time hot summer we...\n",
      "3      Basically family little boy Jake thinks zombie...\n",
      "4      Petter Mattei Love Time Money visually stunnin...\n",
      "                             ...                        \n",
      "194    watched mask currently showing Fox Kids late n...\n",
      "195    Phantasm Class Phantasm II awesome Phantasm II...\n",
      "196    Ludicrous Angelic year old Annakin turns whiny...\n",
      "197    Scotty Grant Cramer would star great B movie K...\n",
      "198    keep rigid historical perspective film actuall...\n",
      "Name: review_processed, Length: 199, dtype: object\n",
      "\n",
      "After word tokenization:\n",
      "0      [One, reviewers, mentioned, watching, episode,...\n",
      "1      [wonderful, little, production, br, br, filmin...\n",
      "2      [thought, wonderful, way, spend, time, hot, su...\n",
      "3      [Basically, family, little, boy, Jake, thinks,...\n",
      "4      [Petter, Mattei, Love, Time, Money, visually, ...\n",
      "                             ...                        \n",
      "194    [watched, mask, currently, showing, Fox, Kids,...\n",
      "195    [Phantasm, Class, Phantasm, II, awesome, Phant...\n",
      "196    [Ludicrous, Angelic, year, old, Annakin, turns...\n",
      "197    [Scotty, Grant, Cramer, would, star, great, B,...\n",
      "198    [keep, rigid, historical, perspective, film, a...\n",
      "Name: review_processed, Length: 199, dtype: object\n",
      "\n",
      "After POS tagging:\n",
      "0      [(One, CD), (reviewers, NNS), (mentioned, VBD)...\n",
      "1      [(wonderful, JJ), (little, JJ), (production, N...\n",
      "2      [(thought, VBN), (wonderful, JJ), (way, NN), (...\n",
      "3      [(Basically, NNP), (family, NN), (little, JJ),...\n",
      "4      [(Petter, NNP), (Mattei, NNP), (Love, NNP), (T...\n",
      "                             ...                        \n",
      "194    [(watched, VBN), (mask, NNS), (currently, RB),...\n",
      "195    [(Phantasm, NNP), (Class, NNP), (Phantasm, NNP...\n",
      "196    [(Ludicrous, JJ), (Angelic, NNP), (year, NN), ...\n",
      "197    [(Scotty, NNP), (Grant, NNP), (Cramer, NNP), (...\n",
      "198    [(keep, VB), (rigid, JJ), (historical, JJ), (p...\n",
      "Name: review_processed, Length: 199, dtype: object\n",
      "\n",
      "After lemmatization:\n",
      "0      [One, reviewer, mention, watch, episode, hook,...\n",
      "1      [wonderful, little, production, br, br, film, ...\n",
      "2      [think, wonderful, way, spend, time, hot, summ...\n",
      "3      [Basically, family, little, boy, Jake, think, ...\n",
      "4      [Petter, Mattei, Love, Time, Money, visually, ...\n",
      "                             ...                        \n",
      "194    [watch, mask, currently, show, Fox, Kids, late...\n",
      "195    [Phantasm, Class, Phantasm, II, awesome, Phant...\n",
      "196    [Ludicrous, Angelic, year, old, Annakin, turn,...\n",
      "197    [Scotty, Grant, Cramer, would, star, great, B,...\n",
      "198    [keep, rigid, historical, perspective, film, a...\n",
      "Name: review_processed, Length: 199, dtype: object\n",
      "\n",
      "After stemming:\n",
      "0      [(One, n), (reviewer, n), (mention, n), (watch...\n",
      "1      [(wonderful, n), (little, n), (production, n),...\n",
      "2      [(think, v), (wonderful, n), (way, n), (spend,...\n",
      "3      [(Basically, n), (family, n), (little, n), (bo...\n",
      "4      [(Petter, n), (Mattei, n), (Love, n), (Time, n...\n",
      "                             ...                        \n",
      "194    [(watch, n), (mask, n), (currently, r), (show,...\n",
      "195    [(Phantasm, n), (Class, n), (Phantasm, n), (II...\n",
      "196    [(Ludicrous, n), (Angelic, n), (year, n), (old...\n",
      "197    [(Scotty, n), (Grant, n), (Cramer, n), (would,...\n",
      "198    [(keep, v), (rigid, n), (historical, n), (pers...\n",
      "Name: review_processed, Length: 199, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "ds = pd.read_csv(\"c:/Users/dell/Desktop/Projects/Sentiment Analysis/sentiment analysis/IMDB Dataset.csv\")\n",
    "ds = ds.dropna()\n",
    "\n",
    "ds['review_processed'] = ds['review'].apply(lambda x: \" \".join([w for w in x.split() if len(w) > 2]))\n",
    "ds = ds[['review', 'review_processed', 'sentiment']]\n",
    "ds['review_processed'] = ds['review_processed'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(rev):\n",
    "    text_tokenized = word_tokenize(rev)\n",
    "    rev_new = [i for i in text_tokenized if i.lower() not in stop_words]\n",
    "    return \" \".join(rev_new)\n",
    "\n",
    "ds['review_processed'] = ds['review_processed'].apply(remove_stopwords)\n",
    "print(\"After removing stopwords:\")\n",
    "print(ds['review_processed'])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def imdb_lemmatize(words):\n",
    "    imdb_2 = []\n",
    "    for word, pos in words:\n",
    "        pos = imdb_lemmatize_pos(pos)\n",
    "        imdb_2.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "    return imdb_2\n",
    "\n",
    "def imdb_lemmatize_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "ds['review_processed'] = ds['review_processed'].apply(word_tokenize)\n",
    "print(\"\\nAfter word tokenization:\")\n",
    "print(ds['review_processed'])\n",
    "\n",
    "ds['review_processed'] = ds['review_processed'].apply(pos_tag)\n",
    "print(\"\\nAfter POS tagging:\")\n",
    "print(ds['review_processed'])\n",
    "\n",
    "ds['review_processed'] = ds['review_processed'].apply(imdb_lemmatize)\n",
    "print(\"\\nAfter lemmatization:\")\n",
    "print(ds['review_processed'])\n",
    "\n",
    "def stemming(words):\n",
    "    pr = []\n",
    "    if isinstance(words, str):\n",
    "        words = word_tokenize(words)\n",
    "    for word, pos in pos_tag(words):\n",
    "        if pos[0].lower() not in ['a', 'r', 'n', 'v']:\n",
    "            pr.append((word, 'n'))\n",
    "        else:\n",
    "            pr.append((word, pos[0].lower()))\n",
    "    return pr\n",
    "\n",
    "ds['review_processed'] = ds['review_processed'].apply(stemming)\n",
    "print(\"\\nAfter stemming:\")\n",
    "print(ds['review_processed'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
